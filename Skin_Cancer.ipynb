{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1648461468281,
     "user": {
      "displayName": "Himanshi Meswal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghu9YuOnRlAjCDVpBE62SkoXJVlqYXiS7R3ohPyXIo=s64",
      "userId": "03497991588978686290"
     },
     "user_tz": -330
    },
    "id": "em7EpAFaaUnq"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from keras.layers import Input, Lambda, Dense, Flatten, Dropout\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "import keras\n",
    "import cv2\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1648461468282,
     "user": {
      "displayName": "Himanshi Meswal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghu9YuOnRlAjCDVpBE62SkoXJVlqYXiS7R3ohPyXIo=s64",
      "userId": "03497991588978686290"
     },
     "user_tz": -330
    },
    "id": "Ya2Yab1Gean-",
    "outputId": "6db5e95f-a3dc-4c5b-c782-6fa1fca322fe"
   },
   "outputs": [],
   "source": [
    "# re-size all the images to this\n",
    "IMAGE_SIZE = [170, 170]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 45216,
     "status": "ok",
     "timestamp": 1648461513476,
     "user": {
      "displayName": "Himanshi Meswal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghu9YuOnRlAjCDVpBE62SkoXJVlqYXiS7R3ohPyXIo=s64",
      "userId": "03497991588978686290"
     },
     "user_tz": -330
    },
    "id": "rugJRusGfcR1",
    "outputId": "4f4fc6ec-1466-4e9b-b8f6-f936d4294492"
   },
   "outputs": [],
   "source": [
    "SIZE = 170"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 97,
     "status": "ok",
     "timestamp": 1648461513479,
     "user": {
      "displayName": "Himanshi Meswal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghu9YuOnRlAjCDVpBE62SkoXJVlqYXiS7R3ohPyXIo=s64",
      "userId": "03497991588978686290"
     },
     "user_tz": -330
    },
    "id": "R4dbv2iVfbrW"
   },
   "outputs": [],
   "source": [
    "all_images = []\n",
    "all_labels = [] \n",
    "for directory_path in glob.glob(\"../input/cancer-himanshi/cancer/*\"):\n",
    "    label = directory_path.split(\"\\\\\")[-1]\n",
    "    print(label)\n",
    "    for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
    "        print(img_path)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)       \n",
    "        img = cv2.resize(img, (SIZE, SIZE))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        all_images.append(img)\n",
    "        all_labels.append(label)\n",
    "\n",
    "all_images = np.array(all_images)\n",
    "all_labels = np.array(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(all_images, all_labels, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode labels from text to integers.\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_test)\n",
    "test_labels_encoded = le.transform(y_test)\n",
    "le.fit(y_train)\n",
    "train_labels_encoded = le.transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = x_train, train_labels_encoded, x_test, test_labels_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 80,
     "status": "ok",
     "timestamp": 1648461513480,
     "user": {
      "displayName": "Himanshi Meswal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghu9YuOnRlAjCDVpBE62SkoXJVlqYXiS7R3ohPyXIo=s64",
      "userId": "03497991588978686290"
     },
     "user_tz": -330
    },
    "id": "Wji5fFIKfbZS",
    "outputId": "4be11484-dc19-44d9-92ae-6e5e20c66691"
   },
   "outputs": [],
   "source": [
    "#One hot encode y values for neural network. \n",
    "\n",
    "y_train_one_hot = to_categorical(y_train)\n",
    "y_test_one_hot = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***model 1 - InceptionV3***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d4wLM8kTfbWJ"
   },
   "outputs": [],
   "source": [
    "# add preprocessing layer to the front of inceptionV3\n",
    "inception = InceptionV3(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5yg2XSa8fbSr"
   },
   "outputs": [],
   "source": [
    "# don't train existing weights\n",
    "for layer in inception.layers:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x1H2lciZfbQG"
   },
   "outputs": [],
   "source": [
    "# our layers - you can add more if you want\n",
    "x = Flatten()(inception.output)\n",
    "# x = Denase(1000, activation='relu')(x)\n",
    "prediction = Dense(4, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D-8Se6PtfbNd"
   },
   "outputs": [],
   "source": [
    "# create a model object\n",
    "model1 = Model(inputs=inception.input, outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t42Pwp4MfbKY"
   },
   "outputs": [],
   "source": [
    "# view the structure of the model\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h3wOX2VlfbGK"
   },
   "outputs": [],
   "source": [
    "# tell the model what cost and optimization method to use\n",
    "model1.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    mode='min',\n",
    "    patience=5,restore_best_weights=True)\n",
    "#Train the CNN model\n",
    "r1 = model1.fit(x_train, y_train_one_hot, epochs=11, callbacks=[earlystop], validation_data = (x_test, y_test_one_hot))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Model 2 - MobileNet***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet import MobileNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add preprocessing layer to the front of mobilenet\n",
    "mobilenet = MobileNet(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't train existing weights\n",
    "for layer in mobilenet.layers:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our layers - you can add more if you want\n",
    "x = Flatten()(mobilenet.output)\n",
    "# x = Denase(1000, activation='relu')(x)\n",
    "prediction = Dense(4, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model object\n",
    "model2 = Model(inputs=mobilenet.input, outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the structure of the model\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tell the model what cost and optimization method to use\n",
    "model2.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    mode='min',\n",
    "    patience=5,restore_best_weights=True)\n",
    "#Train the CNN model\n",
    "r2 = model2.fit(x_train, y_train_one_hot, epochs=11, callbacks=[earlystop], validation_data = (x_test, y_test_one_hot))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Model 3 - Xception***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.xception import Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add preprocessing layer to the front of VGG\n",
    "xception = Xception(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't train existing weights\n",
    "for layer in xception.layers:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our layers - you can add more if you want\n",
    "x = Flatten()(xception.output)\n",
    "# x = Denase(1000, activation='relu')(x)\n",
    "prediction = Dense(4, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model object\n",
    "model3 = Model(inputs=xception.input, outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the structure of the model\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tell the model what cost and optimization method to use\n",
    "model3.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    mode='min',\n",
    "    patience=5,restore_best_weights=True)\n",
    "#Train the CNN model\n",
    "r3 = model3.fit(x_train, y_train_one_hot, epochs=11, callbacks=[earlystop], validation_data = (x_test, y_test_one_hot))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Model4 - VGG16***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add preprocessing layer to the front of VGG\n",
    "vgg16 = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "\n",
    "# don't train existing weights\n",
    "for layer in vgg16.layers:\n",
    "  layer.trainable = False\n",
    "\n",
    "# our layers - you can add more if you want\n",
    "x = Flatten()(vgg16.output)\n",
    "# x = Denase(1000, activation='relu')(x)\n",
    "prediction = Dense(4, activation='softmax')(x)\n",
    "\n",
    "# create a model object\n",
    "model4 = Model(inputs=vgg16.input, outputs=prediction)\n",
    "\n",
    "# view the structure of the model\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tell the model what cost and optimization method to use\n",
    "model4.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    mode='min',\n",
    "    patience=5,restore_best_weights=True)\n",
    "#Train the CNN model\n",
    "r4 = model4.fit(x_train, y_train_one_hot, epochs=11, callbacks=[earlystop], validation_data = (x_test, y_test_one_hot))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Model5 - CNN***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "\n",
    "model5 = Sequential()\n",
    "model5.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=IMAGE_SIZE + [3]))\n",
    "model5.add(BatchNormalization())\n",
    "\n",
    "model5.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "model5.add(BatchNormalization())\n",
    "model5.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model5.add(Dropout(0.25))\n",
    "\n",
    "model5.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model5.add(BatchNormalization())\n",
    "model5.add(Dropout(0.25))\n",
    "\n",
    "model5.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model5.add(BatchNormalization())\n",
    "model5.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model5.add(Dropout(0.25))\n",
    "\n",
    "model5.add(Flatten())\n",
    "\n",
    "model5.add(Dense(512, activation='relu'))\n",
    "model5.add(BatchNormalization())\n",
    "model5.add(Dropout(0.5))\n",
    "\n",
    "model5.add(Dense(128, activation='relu'))\n",
    "model5.add(BatchNormalization())\n",
    "model5.add(Dropout(0.5))\n",
    "\n",
    "model5.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model5.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model5.summary()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    mode='min',\n",
    "    patience=5,restore_best_weights=True)\n",
    "#Train the CNN model\n",
    "r5 = model5.fit(x_train, y_train_one_hot, epochs=11, callbacks=[earlystop], validation_data = (x_test, y_test_one_hot))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Model6 - ResNet101V2***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet_v2 import ResNet101V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add preprocessing layer to the front of VGG\n",
    "resnet = ResNet101V2(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "\n",
    "# don't train existing weights\n",
    "for layer in resnet.layers:\n",
    "  layer.trainable = False\n",
    "\n",
    "# our layers - you can add more if you want\n",
    "x = Flatten()(resnet.output)\n",
    "# x = Denase(1000, activation='relu')(x)\n",
    "prediction = Dense(4, activation='softmax')(x)\n",
    "\n",
    "# create a model object\n",
    "model6 = Model(inputs=resnet.input, outputs=prediction)\n",
    "\n",
    "# view the structure of the model\n",
    "model6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tell the model what cost and optimization method to use\n",
    "model6.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    mode='min',\n",
    "    patience=5,restore_best_weights=True)\n",
    "#Train the CNN model\n",
    "r6 = model6.fit(x_train, y_train_one_hot, epochs=11, callbacks=[earlystop], validation_data = (x_test, y_test_one_hot))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Model7 - EfficientNetB4***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientnet.keras import EfficientNetB4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add preprocessing layer to the front of VGG\n",
    "efficientnet = EfficientNetB4(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "\n",
    "# don't train existing weights\n",
    "for layer in efficientnet.layers:\n",
    "  layer.trainable = False\n",
    "\n",
    "# our layers - you can add more if you want\n",
    "x = Flatten()(efficientnet.output)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# x = Denase(1000, activation='relu')(x)\n",
    "prediction = Dense(4, activation='softmax')(x)\n",
    "\n",
    "# create a model object\n",
    "model7 = Model(inputs=efficientnet.input, outputs=prediction)\n",
    "\n",
    "# view the structure of the model\n",
    "model7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tell the model what cost and optimization method to use\n",
    "model7.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    mode='min',\n",
    "    patience=5,restore_best_weights=True)\n",
    "#Train the CNN model\n",
    "r7 = model7.fit(x_train, y_train_one_hot, epochs=11, callbacks=[earlystop], validation_data = (x_test, y_test_one_hot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Accuracy***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('test_accuracy 1: {:.2f}%'.format(model1.evaluate(np.array(x_test),np.array(y_test_one_hot))[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('test_accuracy 2: {:.2f}%'.format(model2.evaluate(np.array(x_test),np.array(y_test_one_hot))[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('test_accuracy 3: {:.2f}%'.format(model3.evaluate(np.array(x_test),np.array(y_test_one_hot))[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('test_accuracy 4: {:.2f}%'.format(model4.evaluate(np.array(x_test),np.array(y_test_one_hot))[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('test_accuracy 5: {:.2f}%'.format(model5.evaluate(np.array(x_test),np.array(y_test_one_hot))[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('test_accuracy 6: {:.2f}%'.format(model5.evaluate(np.array(x_test),np.array(y_test_one_hot))[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('test_accuracy 7: {:.2f}%'.format(model5.evaluate(np.array(x_test),np.array(y_test_one_hot))[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model1, model2, model3, model4, model5, model6, model7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [model.predict(x_test) for model in models]\n",
    "preds=np.array(preds)\n",
    "summed = np.sum(preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# argmax across classes\n",
    "ensemble_prediction = np.argmax(summed, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_accuracy = accuracy_score(y_test, ensemble_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model1, model2, model3, model4, model5, model6, model7]\n",
    "preds_w = [model.predict(x_test) for model in models]\n",
    "preds_w=np.array(preds_w)\n",
    "weights = [0.0, 0.3, 0.3, 0.3, 0.4, 0.3, 0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use tensordot to sum the products of all elements over specified axes.\n",
    "weighted_preds = np.tensordot(preds_w, weights, axes=((0),(0)))\n",
    "weighted_ensemble_prediction = np.argmax(weighted_preds, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_accuracy = accuracy_score(y_test, weighted_ensemble_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy Score for average ensemble = ', ensemble_accuracy)\n",
    "print('Accuracy Score for weighted average ensemble = ', weighted_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_labels_encoded, ensemble_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_labels_encoded, weighted_ensemble_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "#Confusion Matrix - verify accuracy of each class\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(test_labels_encoded, ensemble_prediction)\n",
    "print(cm)\n",
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix - verify accuracy of each class\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(test_labels_encoded, weighted_ensemble_prediction)\n",
    "print(cm)\n",
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model1, model2, model3, model4, model5, model6, model7]\n",
    "preds1 = [model.predict(x_test) for model in models]\n",
    "preds1=np.array(preds1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame([])\n",
    "\n",
    "for w1 in range(0, 5):\n",
    "    for w2 in range(0,5):\n",
    "        for w3 in range(0,5):\n",
    "            for w4 in range(0,5):\n",
    "                for w5 in range(0,5):\n",
    "                    for w6 in range(0,5):\n",
    "                        for w7 in range(0,5):\n",
    "                            wts = [w1/10.,w2/10.,w3/10., w4/10., w5/10.,w6/10., w7/10.]\n",
    "                            wted_preds1 = np.tensordot(preds1, wts, axes=((0),(0)))\n",
    "                            wted_ensemble_pred = np.argmax(wted_preds1, axis=1)\n",
    "                            weighted_accuracy = accuracy_score(y_test, wted_ensemble_pred)\n",
    "                            df = df.append(pd.DataFrame({'wt1':wts[0],'wt2':wts[1], \n",
    "                                                         'wt3':wts[2],'wt4':wts[3],'wt5':wts[4],'wt6':wts[5],'wt7':wts[6], 'acc':weighted_accuracy*100}, index=[0]), ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_acc_row = df.iloc[df['acc'].idxmax()]\n",
    "print(\"Max accuracy of \", max_acc_row[0], \"w1=\", max_acc_row[1],\n",
    "      \" w2=\", max_acc_row[2],\" w3=\", max_acc_row[3],\" w4=\", max_acc_row[4],\" w5=\", max_acc_row[5],\" w6=\", max_acc_row[6], \" and w7=\", max_acc_row[7)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
